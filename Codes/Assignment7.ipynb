{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pOqLHDjrIBzB"
   },
   "outputs": [],
   "source": [
    "data = \"There were also many a night where Elise would sit with her son as he slept, meticulously piecing back together the tears that threatened the blanket entirely, wishing there was a way she could also mend her son. The room would be completely quiet save for the sound of Elise’s song. It was something she had done since she was his age. Inadvertently yet intentionally she would let the air slip through her lips, creating a tune just for him that would live for that moment, replaced the next time by one equally beautiful and equally unique.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFoIWh0HHain",
    "outputId": "30647cf5-5224-46f5-8d53-fffce5b4e26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/nltk-3.6.7-py3-none-any.whl\n",
      "Collecting joblib\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/joblib-1.1.0-py2.py3-none-any.whl\n",
      "Collecting regex>=2021.8.3\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/regex-2022.3.15-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting click\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/click-8.0.4-py3-none-any.whl\n",
      "Collecting tqdm\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/tqdm-4.64.0-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/importlib_metadata-4.8.3-py3-none-any.whl\n",
      "Collecting importlib-resources\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/importlib_resources-5.4.0-py3-none-any.whl\n",
      "Collecting zipp>=0.5\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/zipp-3.6.0-py3-none-any.whl\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  File was already downloaded /home/pict/Desktop/31146_Assignments/typing_extensions-4.1.1-py3-none-any.whl\n",
      "Successfully downloaded nltk regex click joblib tqdm importlib-metadata importlib-resources typing-extensions zipp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pict/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/pict/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pict/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to /home/pict/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/pict/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip download nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "word_stemmer = PorterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading owm-1.4: Package 'owm-1.4' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('owm-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTtcJyB0Hr7Z",
    "outputId": "c4d99636-87b6-449c-c150-60f05ea9de87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'were', 'also', 'many', 'a', 'night', 'where', 'Elise', 'would', 'sit', 'with', 'her', 'son', 'as', 'he', 'slept', ',', 'meticulously', 'piecing', 'back', 'together', 'the', 'tears', 'that', 'threatened', 'the', 'blanket', 'entirely', ',', 'wishing', 'there', 'was', 'a', 'way', 'she', 'could', 'also', 'mend', 'her', 'son', '.', 'The', 'room', 'would', 'be', 'completely', 'quiet', 'save', 'for', 'the', 'sound', 'of', 'Elise', '’', 's', 'song', '.', 'It', 'was', 'something', 'she', 'had', 'done', 'since', 'she', 'was', 'his', 'age', '.', 'Inadvertently', 'yet', 'intentionally', 'she', 'would', 'let', 'the', 'air', 'slip', 'through', 'her', 'lips', ',', 'creating', 'a', 'tune', 'just', 'for', 'him', 'that', 'would', 'live', 'for', 'that', 'moment', ',', 'replaced', 'the', 'next', 'time', 'by', 'one', 'equally', 'beautiful', 'and', 'equally', 'unique', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokened_sen = word_tokenize(data)\n",
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21MUGBlgImnp",
    "outputId": "2d481d33-0ae8-4b03-8728-17dbfd82d329"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('There', 'EX'),\n",
       " ('were', 'VBD'),\n",
       " ('also', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('a', 'DT'),\n",
       " ('night', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('Elise', 'NNP'),\n",
       " ('would', 'MD'),\n",
       " ('sit', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('her', 'PRP$'),\n",
       " ('son', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('slept', 'VBD'),\n",
       " (',', ','),\n",
       " ('meticulously', 'RB'),\n",
       " ('piecing', 'VBG'),\n",
       " ('back', 'RP'),\n",
       " ('together', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('tears', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('threatened', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('blanket', 'NN'),\n",
       " ('entirely', 'RB'),\n",
       " (',', ','),\n",
       " ('wishing', 'VBG'),\n",
       " ('there', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('she', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " ('also', 'RB'),\n",
       " ('mend', 'VB'),\n",
       " ('her', 'PRP$'),\n",
       " ('son', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('room', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('completely', 'RB'),\n",
       " ('quiet', 'JJ'),\n",
       " ('save', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('sound', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Elise', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('song', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('something', 'NN'),\n",
       " ('she', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('done', 'VBN'),\n",
       " ('since', 'IN'),\n",
       " ('she', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('his', 'PRP$'),\n",
       " ('age', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Inadvertently', 'RB'),\n",
       " ('yet', 'RB'),\n",
       " ('intentionally', 'RB'),\n",
       " ('she', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('let', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('air', 'NN'),\n",
       " ('slip', 'NN'),\n",
       " ('through', 'IN'),\n",
       " ('her', 'PRP$'),\n",
       " ('lips', 'NNS'),\n",
       " (',', ','),\n",
       " ('creating', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('tune', 'NN'),\n",
       " ('just', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('him', 'PRP'),\n",
       " ('that', 'WDT'),\n",
       " ('would', 'MD'),\n",
       " ('live', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('moment', 'NN'),\n",
       " (',', ','),\n",
       " ('replaced', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('next', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('equally', 'RB'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('equally', 'RB'),\n",
       " ('unique', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(tokened_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPaFFV7iJvCG",
    "outputId": "29122047-acef-47c0-9773-941a054874df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'also', 'many', 'night', 'Elise', 'would', 'sit', 'son', 'slept', ',', 'meticulously', 'piecing', 'back', 'together', 'tears', 'threatened', 'blanket', 'entirely', ',', 'wishing', 'way', 'could', 'also', 'mend', 'son', '.', 'The', 'room', 'would', 'completely', 'quiet', 'save', 'sound', 'Elise', '’', 'song', '.', 'It', 'something', 'done', 'since', 'age', '.', 'Inadvertently', 'yet', 'intentionally', 'would', 'let', 'air', 'slip', 'lips', ',', 'creating', 'tune', 'would', 'live', 'moment', ',', 'replaced', 'next', 'time', 'one', 'equally', 'beautiful', 'equally', 'unique', '.']\n"
     ]
    }
   ],
   "source": [
    "Filtered_sen = [w for w in tokened_sen if w not in stop_words]\n",
    "print(Filtered_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfx5u7RcK6Ba",
    "outputId": "3b92e43c-0710-4473-f20f-52e1724abdc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There---->there\n",
      "also---->also\n",
      "many---->mani\n",
      "night---->night\n",
      "Elise---->elis\n",
      "would---->would\n",
      "sit---->sit\n",
      "son---->son\n",
      "slept---->slept\n",
      ",---->,\n",
      "meticulously---->meticul\n",
      "piecing---->piec\n",
      "back---->back\n",
      "together---->togeth\n",
      "tears---->tear\n",
      "threatened---->threaten\n",
      "blanket---->blanket\n",
      "entirely---->entir\n",
      ",---->,\n",
      "wishing---->wish\n",
      "way---->way\n",
      "could---->could\n",
      "also---->also\n",
      "mend---->mend\n",
      "son---->son\n",
      ".---->.\n",
      "The---->the\n",
      "room---->room\n",
      "would---->would\n",
      "completely---->complet\n",
      "quiet---->quiet\n",
      "save---->save\n",
      "sound---->sound\n",
      "Elise---->elis\n",
      "’---->’\n",
      "song---->song\n",
      ".---->.\n",
      "It---->it\n",
      "something---->someth\n",
      "done---->done\n",
      "since---->sinc\n",
      "age---->age\n",
      ".---->.\n",
      "Inadvertently---->inadvert\n",
      "yet---->yet\n",
      "intentionally---->intent\n",
      "would---->would\n",
      "let---->let\n",
      "air---->air\n",
      "slip---->slip\n",
      "lips---->lip\n",
      ",---->,\n",
      "creating---->creat\n",
      "tune---->tune\n",
      "would---->would\n",
      "live---->live\n",
      "moment---->moment\n",
      ",---->,\n",
      "replaced---->replac\n",
      "next---->next\n",
      "time---->time\n",
      "one---->one\n",
      "equally---->equal\n",
      "beautiful---->beauti\n",
      "equally---->equal\n",
      "unique---->uniqu\n",
      ".---->.\n"
     ]
    }
   ],
   "source": [
    "for w in Filtered_sen:\n",
    "  print(w + \"---->\"+word_stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yiwpScbyLwIo",
    "outputId": "821edd0d-2b70-4052-bcd3-eea1a0b3c0c1"
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - '/home/pict/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - '/home/pict/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bfed90b4eea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFiltered_sen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"---->\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reader_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# This is where the magic happens!  Transform ourselves into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, omw_reader)\u001b[0m\n\u001b[1;32m   1174\u001b[0m             )\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovenances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momw_prov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# A cache to store the wordnet data of multiple languages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36momw_prov\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mprovdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0mprovdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eng\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_omw_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0mprov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlangfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - '/home/pict/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "for w in Filtered_sen:\n",
    "  print(w + \"---->\"+lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7VKVsTlMFwa",
    "outputId": "ceb79b98-740e-4fb8-97a9-77424ba8a25d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'were', 'also', 'many', 'night', 'where', 'elise', 'would', 'sit', 'with', 'her', 'son', 'as', 'he', 'slept', 'meticulously', 'piecing', 'back', 'together', 'the', 'tears', 'that', 'threatened', 'the', 'blanket', 'entirely', 'wishing', 'there', 'was', 'way', 'she', 'could', 'also', 'mend', 'her', 'son', 'the', 'room', 'would', 'be', 'completely', 'quiet', 'save', 'for', 'the', 'sound', 'of', 'elise', 'song', 'it', 'was', 'something', 'she', 'had', 'done', 'since', 'she', 'was', 'his', 'age', 'inadvertently', 'yet', 'intentionally', 'she', 'would', 'let', 'the', 'air', 'slip', 'through', 'her', 'lips', 'creating', 'tune', 'just', 'for', 'him', 'that', 'would', 'live', 'for', 'that', 'moment', 'replaced', 'the', 'next', 'time', 'by', 'one', 'equally', 'beautiful', 'and', 'equally', 'unique']\n"
     ]
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "X = vectorizer.fit_transform(data.split('.'))\n",
    "print(analyze(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3LgK-AtNPPx",
    "outputId": "cb8b39ea-c496-4772-a711-8d06e4eb1d7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "idf values:\n",
      "age : 2.09861228866811\n",
      "air : 2.09861228866811\n",
      "also : 2.09861228866811\n",
      "and : 2.09861228866811\n",
      "as : 2.09861228866811\n",
      "back : 2.09861228866811\n",
      "be : 2.09861228866811\n",
      "beautiful : 2.09861228866811\n",
      "blanket : 2.09861228866811\n",
      "by : 2.09861228866811\n",
      "completely : 2.09861228866811\n",
      "could : 2.09861228866811\n",
      "creating : 2.09861228866811\n",
      "done : 2.09861228866811\n",
      "elise : 1.6931471805599454\n",
      "entirely : 2.09861228866811\n",
      "equally : 2.09861228866811\n",
      "for : 1.6931471805599454\n",
      "had : 2.09861228866811\n",
      "he : 2.09861228866811\n",
      "her : 1.6931471805599454\n",
      "him : 2.09861228866811\n",
      "his : 2.09861228866811\n",
      "inadvertently : 2.09861228866811\n",
      "intentionally : 2.09861228866811\n",
      "it : 2.09861228866811\n",
      "just : 2.09861228866811\n",
      "let : 2.09861228866811\n",
      "lips : 2.09861228866811\n",
      "live : 2.09861228866811\n",
      "many : 2.09861228866811\n",
      "mend : 2.09861228866811\n",
      "meticulously : 2.09861228866811\n",
      "moment : 2.09861228866811\n",
      "next : 2.09861228866811\n",
      "night : 2.09861228866811\n",
      "of : 2.09861228866811\n",
      "one : 2.09861228866811\n",
      "piecing : 2.09861228866811\n",
      "quiet : 2.09861228866811\n",
      "replaced : 2.09861228866811\n",
      "room : 2.09861228866811\n",
      "save : 2.09861228866811\n",
      "she : 1.4054651081081644\n",
      "since : 2.09861228866811\n",
      "sit : 2.09861228866811\n",
      "slept : 2.09861228866811\n",
      "slip : 2.09861228866811\n",
      "something : 2.09861228866811\n",
      "son : 2.09861228866811\n",
      "song : 2.09861228866811\n",
      "sound : 2.09861228866811\n",
      "tears : 2.09861228866811\n",
      "that : 1.6931471805599454\n",
      "the : 1.4054651081081644\n",
      "there : 2.09861228866811\n",
      "threatened : 2.09861228866811\n",
      "through : 2.09861228866811\n",
      "time : 2.09861228866811\n",
      "together : 2.09861228866811\n",
      "tune : 2.09861228866811\n",
      "unique : 2.09861228866811\n",
      "was : 1.6931471805599454\n",
      "way : 2.09861228866811\n",
      "were : 2.09861228866811\n",
      "where : 2.09861228866811\n",
      "wishing : 2.09861228866811\n",
      "with : 2.09861228866811\n",
      "would : 1.4054651081081644\n",
      "yet : 2.09861228866811\n"
     ]
    }
   ],
   "source": [
    "print('\\nidf values:')\n",
    "for ele1, ele2 in zip(vectorizer.get_feature_names(), vectorizer.idf_):\n",
    "    print(ele1, ':', ele2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TD8Ue-DCOe9P",
    "outputId": "735b85ee-f0dc-46a0-9e63-ad0c05e35c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word indexes:\n",
      "{'there': 55, 'were': 64, 'also': 2, 'many': 30, 'night': 35, 'where': 65, 'elise': 14, 'would': 68, 'sit': 45, 'with': 67, 'her': 20, 'son': 49, 'as': 4, 'he': 19, 'slept': 46, 'meticulously': 32, 'piecing': 38, 'back': 5, 'together': 59, 'the': 54, 'tears': 52, 'that': 53, 'threatened': 56, 'blanket': 8, 'entirely': 15, 'wishing': 66, 'was': 62, 'way': 63, 'she': 43, 'could': 11, 'mend': 31, 'room': 41, 'be': 6, 'completely': 10, 'quiet': 39, 'save': 42, 'for': 17, 'sound': 51, 'of': 36, 'song': 50, 'it': 25, 'something': 48, 'had': 18, 'done': 13, 'since': 44, 'his': 22, 'age': 0, 'inadvertently': 23, 'yet': 69, 'intentionally': 24, 'let': 27, 'air': 1, 'slip': 47, 'through': 57, 'lips': 28, 'creating': 12, 'tune': 60, 'just': 26, 'him': 21, 'live': 29, 'moment': 33, 'replaced': 40, 'next': 34, 'time': 58, 'by': 9, 'one': 37, 'equally': 16, 'beautiful': 7, 'and': 3, 'unique': 61}\n",
      "\n",
      "tf-idf value:\n",
      "  (0, 31)\t0.15762698682993861\n",
      "  (0, 11)\t0.15762698682993861\n",
      "  (0, 43)\t0.105564630152006\n",
      "  (0, 63)\t0.15762698682993861\n",
      "  (0, 62)\t0.12717246047417838\n",
      "  (0, 66)\t0.15762698682993861\n",
      "  (0, 15)\t0.15762698682993861\n",
      "  (0, 8)\t0.15762698682993861\n",
      "  (0, 56)\t0.15762698682993861\n",
      "  (0, 53)\t0.12717246047417838\n",
      "  (0, 52)\t0.15762698682993861\n",
      "  (0, 54)\t0.211129260304012\n",
      "  (0, 59)\t0.15762698682993861\n",
      "  (0, 5)\t0.15762698682993861\n",
      "  (0, 38)\t0.15762698682993861\n",
      "  (0, 32)\t0.15762698682993861\n",
      "  (0, 46)\t0.15762698682993861\n",
      "  (0, 19)\t0.15762698682993861\n",
      "  (0, 4)\t0.15762698682993861\n",
      "  (0, 49)\t0.31525397365987723\n",
      "  (0, 20)\t0.25434492094835676\n",
      "  (0, 67)\t0.15762698682993861\n",
      "  (0, 45)\t0.15762698682993861\n",
      "  (0, 68)\t0.105564630152006\n",
      "  (0, 14)\t0.12717246047417838\n",
      "  :\t:\n",
      "  (3, 37)\t0.1669105620486018\n",
      "  (3, 9)\t0.1669105620486018\n",
      "  (3, 58)\t0.1669105620486018\n",
      "  (3, 34)\t0.1669105620486018\n",
      "  (3, 40)\t0.1669105620486018\n",
      "  (3, 33)\t0.1669105620486018\n",
      "  (3, 29)\t0.1669105620486018\n",
      "  (3, 21)\t0.1669105620486018\n",
      "  (3, 26)\t0.1669105620486018\n",
      "  (3, 60)\t0.1669105620486018\n",
      "  (3, 12)\t0.1669105620486018\n",
      "  (3, 28)\t0.1669105620486018\n",
      "  (3, 57)\t0.1669105620486018\n",
      "  (3, 47)\t0.1669105620486018\n",
      "  (3, 1)\t0.1669105620486018\n",
      "  (3, 27)\t0.1669105620486018\n",
      "  (3, 24)\t0.1669105620486018\n",
      "  (3, 69)\t0.1669105620486018\n",
      "  (3, 23)\t0.1669105620486018\n",
      "  (3, 17)\t0.26932478101290586\n",
      "  (3, 43)\t0.11178194867185966\n",
      "  (3, 53)\t0.26932478101290586\n",
      "  (3, 54)\t0.22356389734371931\n",
      "  (3, 20)\t0.13466239050645293\n",
      "  (3, 68)\t0.22356389734371931\n",
      "\n",
      "tf-idf values in matrix form:\n",
      "[[0.         0.         0.31525397 0.         0.15762699 0.15762699\n",
      "  0.         0.         0.15762699 0.         0.         0.15762699\n",
      "  0.         0.         0.12717246 0.15762699 0.         0.\n",
      "  0.         0.15762699 0.25434492 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15762699 0.15762699 0.15762699 0.         0.         0.15762699\n",
      "  0.         0.         0.15762699 0.         0.         0.\n",
      "  0.         0.10556463 0.         0.15762699 0.15762699 0.\n",
      "  0.         0.31525397 0.         0.         0.15762699 0.12717246\n",
      "  0.21112926 0.31525397 0.15762699 0.         0.         0.15762699\n",
      "  0.         0.         0.12717246 0.15762699 0.15762699 0.15762699\n",
      "  0.15762699 0.15762699 0.10556463 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.29431629 0.         0.         0.         0.29431629 0.\n",
      "  0.         0.         0.23745253 0.         0.         0.23745253\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29431629 0.         0.         0.29431629 0.         0.29431629\n",
      "  0.29431629 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29431629 0.29431629 0.         0.\n",
      "  0.3942141  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.19710705 0.        ]\n",
      " [0.29620407 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.29620407 0.         0.         0.         0.\n",
      "  0.29620407 0.         0.         0.         0.29620407 0.\n",
      "  0.         0.29620407 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.39674264 0.29620407 0.         0.         0.\n",
      "  0.29620407 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.47795116 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.16691056 0.         0.16691056 0.         0.\n",
      "  0.         0.16691056 0.         0.16691056 0.         0.\n",
      "  0.16691056 0.         0.         0.         0.33382112 0.26932478\n",
      "  0.         0.         0.13466239 0.16691056 0.         0.16691056\n",
      "  0.16691056 0.         0.16691056 0.16691056 0.16691056 0.16691056\n",
      "  0.         0.         0.         0.16691056 0.16691056 0.\n",
      "  0.         0.16691056 0.         0.         0.16691056 0.\n",
      "  0.         0.11178195 0.         0.         0.         0.16691056\n",
      "  0.         0.         0.         0.         0.         0.26932478\n",
      "  0.2235639  0.         0.         0.16691056 0.16691056 0.\n",
      "  0.16691056 0.16691056 0.         0.         0.         0.\n",
      "  0.         0.         0.2235639  0.16691056]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nWord indexes:')\n",
    "print(vectorizer.vocabulary_)\n",
    "  \n",
    "# display tf-idf values\n",
    "print('\\ntf-idf value:')\n",
    "print(X)\n",
    "  \n",
    "# in matrix form\n",
    "print('\\ntf-idf values in matrix form:')\n",
    "print(X.toarray())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "31424_Assignment7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
